## 动机

大型分布式系统通常以一种模块化的方式实现，往往涉及多个不同的团队，他们使用的技术和编程语言也形形色色。各个组件之间不仅需要可靠地通信，还需要快速、各自独立地更新换代。模块之间高效和易于扩展的通信是分布式系统中备受关注的问题。它显著影响着用户感受到的延迟，以及系统运行所需的资源量。

[反应式宣言](http://www.reactivemanifesto.org)记载了一类架构模式，这种模式偏爱异步消息传递并囊括了不止于请求-响应的多种通信模式，而且已经在[反应式流](http://www.reactive-streams.org)和[反应式扩展](http://reactivex.io)等代码库中实现了。我们的“RSocket”协议便是一个信奉“反应式”原则的形式通信协议。

这一节论述了制定新协议的动机。

#### 消息驱动 (Message Driven)

网络通信是异步的。RSocket 协议信奉这一观点，并把所有的通信建模为单一网络连接上的多路消息流，永远不会在等待响应时同步地阻塞。

[反应式宣言](http://www.reactivemanifesto.org)声明了：

> 反应式系统依靠异步消息传递在组件之间建立边界，以确保松耦合、隔离、位置透明，并提供将错误委托为消息的方法。使用显式消息传递可以通过塑造和监视系统中的消息队列并在必要时应用背压来实现负载管理、弹性和流量控制。。。非阻塞通信允许接收方仅在活动时消耗资源，从而减少系统开销。

此外，[HTTP/2 FAQ](https://http2.github.io/faq/#why-is-http2-multiplexed)很好地解释了在持久连接上采用多路复用形式的面向消息协议的动机：

> HTTP/1.x 存在名为“队头阻塞”的问题，即一个连接同一时间实际上只能处理一个请求。

> HTTP/1.1 尝试用流水线解决这个问题，但是并没有彻底解决（一个庞大或缓慢的响应仍旧会阻塞位于其后的响应）。另外，人们发现流水线非常难以部署，因为很多信息中介和服务器不能正确处理。

> 这迫使客户端使用许多启发式方法（通常是猜测）来确定何时将哪些请求放在到源的哪个连接上；由于页面加载10倍（或更多）可用连接数的情况很常见，这可能会严重影响性能，经常导致阻塞请求的“瀑布”。（译者留言：不懂，机翻的）

> 多路复用通过允许同时存在多个请求和响应消息，解决了这些问题；甚至允许两个消息的不同部分在线路上混杂传输。

> 这反过来让客户端可以在一个源上只使用一个连接来加载页面。

它接着论述起持久连接：

> 使用HTTP/1时，浏览器可以对每个源打开4个或8个连接。由于许多站点使用多个源，加载一个页面可能会打开超过30个连接。

> 一个应用程序同时打开如此多的连接会打破构建TCP的许多假设；由于每个连接都会在响应中涌入大量数据，因此中间网络的缓冲区有溢出的实际风险，从而导致拥塞事件和重传。

> 此外，使用如此多的连接不公平地垄断了网络资源，从其他行为较好的应用程序（例如VoIP）“窃取”了网络资源。

#### 交互模型(Interaction Models)

不合适的协议会增加开发系统的成本。它可能是一个不合适的抽象，却迫使系统的设计变成它的模式。然后，开发人员需要花费额外的时间来解决它的缺点，以处理错误并获得可接受的性能。在使用多种编程语言的环境中，这个问题被放大了，因为不同的语言将使用不同的方法来解决这个问题，并且需要在团队之间进行额外的协调。到目前为止，事实标准是HTTP，一切都是请求/响应。在某些情况下，这可能不是所需功能的理想通信模型。

推送通知就是一个这样的例子。只有请求/响应一招可用，导致应用程序不得不进行轮询，这种情况下客户端持续不断地发送请求获取服务器的数据。我们很容易发现这种情况：应用程序每秒光是为了轮询就发送大量请求，结果却只是得知目前没有任何新数据。这对客户端、服务器和网络来说是一种浪费，不仅要花钱，还会增加基础设施的规模、操作复杂性和可用性。通常，它还会增加接收通知时的用户体验延迟，因为为了降低成本，轮询频率被缩减为更长的间隔。

由于这个和其他一些原因，RSocket并不局限于一个交互模型。下面介绍的各种受支持的交互模型为系统设计开辟了强大的新可能性：


##### 即发即弃(Fire-and-Forget)

即发即弃是一种对请求/响应的改进，在不需要响应时非常有用。它可以带来显著的性能优化，不仅通过跳过响应节省了网络使用，而且还节省了客户端和服务器的处理时间，因为不再需要为了等待和关联响应或取消请求而记录信息。

这个交互模型对于允许丢失的情况很有用，比如非关键事件日志记录。

用法可以这样理解：

```java
// in Java
Future<Void> completionSignalOfSend = socketClient.fireAndForget(message);
```

##### 请求/响应(Request/Response) （单个响应）

标准的请求/响应语义仍然受到支持，而且我们预计它将仍然代表 RSocket 连接上的大多数请求。这些请求/响应交互可以被认为是优化的“只包含一个响应的流”，并且是在单个连接上复用的异步消息。

消费者“等待”响应消息，因此它看起来像一个典型的请求/响应，但在底层它从不同步阻塞。

用法可以这样理解：

```java
Future<Payload> response = socketClient.requestResponse(requestPayload);
```

#### 请求/流(Request/Stream)（多个响应，有限）

由请求/响应可以扩展到请求/流，它允许将多个消息流式返回。可以将其视为一个“集合”或“列表”响应，但不是作为单个响应返回所有数据，而是按顺序流式返回每个元素。

使用例可以包括：

- 获取视频列表
- 获取某个种类的产品列表
- 逐行获取一个文件

用法可以这样理解：

```java
Publisher<Payload> response = socketClient.requestStream(requestPayload);
```

##### 通道

通道是双向的，在两个方向上都有消息流。

可以从中受益的一个使用例是：

- 客户端请求一个数据流，这个流在建立后立即发送大量数据告知客户端当前状态
- 当发生变化时，服务器向客户端发送增量/差异
- 客户端随着时间的推移更新订阅，以添加或删除标准、主题等

如果没有双向通道，客户端不得不取消初始请求，重新请求并从头接收所有数据，而不是仅仅更新订阅并高效地获取差异。

用法可以这样理解：

```java
Publisher<Payload> output = socketClient.requestChannel(Publisher<Payload> input);
```

#### 行为

除了上面的交互模型之外，还有其他行为有益于应用程序和系统效率。

##### 单响应 对比 多响应

单响应和多响应之间的一个关键区别是 RSocket 栈如何向应用程序传递数据：单个响应可能跨多个帧进行传输，并且是一个更大的 RS 连接的一部分，而且该连接此时可能正在传输多个多路消息流。但是单响应意味着应用程序只有在接收到整个响应后才能获得数据。而多响应则是一份一份地传递数据。这可以允许用户在设计服务时考虑多响应，然后客户端可以在接收到第一个数据块后立即开始处理数据。

##### 双向

RSocket 支持双向请求，客户端和服务器都可以作为请求者或响应者。这允许客户端（例如用户设备）充当来自服务器请求的响应器。

例如，服务器可以向客户端查询跟踪调试信息、状态等。服务器可以在需要时才进行查询，而不是让几亿个客户端不停地提交只是偶尔可能需要的数据，从而减少基础设施的扩增需求。这也开创了客户机和服务器之间目前无法想象的未来交互模型。

##### 取消

所有流(包括请求/响应)都支持取消，以便有效地清理服务器(响应器)资源。这意味着当客户端取消或离开时，服务器有机会提前终止工作。这对于流和订阅等交互模型是必不可少的，但对于请求/响应也很有用，可以有效地采用“备份请求”等方法来抑制尾部延迟。（拓展阅读 [1](http://highscalability.com/blog/2012/3/12/google-taming-the-long-latency-tail-when-more-machines-equal.html)，[2](http://highscalability.com/blog/2012/6/18/google-on-latency-tolerant-systems-making-a-predictable-whol.html)，[3](http://www.bailis.org/blog/doing-redundant-work-to-speed-up-distributed-queries/)，[4](http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/people/jeff/Stanford-DL-Nov-2010.pdf)）


#### 可恢复性

对于长期存在的流，特别是那些从移动客户端提供订阅服务的流，如果必须重新建立所有订阅，网络断开可能会严重影响成本和性能。当网络直接发生重新连接，或者在 Wifi 和蜂窝网络之间切换时，这种情况尤其严重。

RSocket 支持会话恢复，允许用一个简单的握手在新的传输连接上恢复客户端/服务器会话。

#### 应用流控

RSocket提供了应用程序级别的流量控制，帮助保护客户端和服务器免于过载。它既适用于数据中心内的服务器到服务器通信，也适用于涉及浏览器、移动电话等的设备到服务器场景。这两种场景都可以从应用流控中获益。

##### “反应式流” （数据流级别）背压

流量控制的第一种形式是在给定的流上施加背压。它是一种受反应式流 [Subscription.request(n)](https://github.com/reactive-streams/reactive-streams-jvm/blob/master/README.md#3-subscription-code) 机制启发的“异步拉取-推送”流控。

很多反应式流代码库，比如
[Reactor](https://github.com/reactor/reactor)，[RxJava](https://github.com/ReactiveX/RxJava/)，[Akka Streams](http://doc.akka.io/docs/akka/2.4/scala/stream/index.html) 以及很多其他的库都实现了这种背压机制。
该机制使服务器和设备能够在给定流内从远程端推回有效负载流。

RSocket 允许 `request(n)` 信号通过网络从请求者发送到响应者（通常是从客户端到服务器）。它在应用层级上根据反应式流语义控制从响应器到请求者的负载流。这支持使用有界缓冲区，因此流的速率将根据应用程序的消耗进行调整，而不仅仅依赖于传输和网络缓冲。

##### 租借（连接级别背压）

流控的第二种形式是限制给定连接中的请求和流的总数。在响应器想要限制并发请求数时可以发挥作用。启用后，响应器（通常是服务器，但不一定是服务器）可以根据自身能力向请求者发放租约，以便控制请求速率。

这也可以用于在具有机器集群的数据中心中启用更智能的路由和负载平衡算法。例如，负载均衡服务器（响应者）可以将其容量发送给代理（请求者）。

#### 多编程语言支持

上面的许多动机都可以通过利用现有的协议、库和技术来实现。然而，这通常需要结合某些必须在跨语言、平台和技术栈上已经达成一致的特定的实现。将交互模型和流控制行为形式化到协议中提供了不同语言实现之间的契约。与无处不在的HTTP/1.1请求/响应相比，这反过来又在更广泛的行为集中改进了多语言交互，同时还支持跨语言的反应式流应用级流控（而不是局限于最初定义反应式流的 Java）。

#### 传输层适应性
（译者按：本协议文档中出现的“传输层”一次和OSI七层模型的“传输层”有一定区别。）

就像 HTTP 请求/响应不是应用程序可以或应该通信的唯一方式一样，TCP 不是唯一可用的传输层，也不是所有用例的最佳传输层。因此，RSocket 允许基于环境、设备能力和性能需求更换底层传输层。RSocket（应用协议）可以面向 WebSockets、TCP 和 [Aeron](https://github.com/real-logic/Aeron)，并且预期可以在任何具有类似 TCP 特性的传输层上使用，比如 [Quic](https://www.chromium.org/quic)。

也许更重要的是，它使 TCP、WebSockets 和 Aeron 无需付出很大的努力就可以投入使用。例如，WebSockets 的使用通常很吸引人，但它仅展现了帧封装语义，因此使用它需要定义应用程序协议。这通常是工作量很庞大，需要大量的努力。而 TCP 甚至不提供帧封装。因此，大多数应用程序最终使用 HTTP/1.1 并牢牢抓住请求/响应不放，而错失了同步式请求/响应之外更多丰富的交互模型带来的好处。

因此，RSocket 在这些网络传输上定义了应用层语义，以便在适当的时候选择它们。在本文档的稍后，我们将简要比较一下在确定需要一个新的应用协议之前，尝试使用 WebSockets 和 Aeron 时所探索的其他协议。

#### 效率与性能

网络资源利用效率低下的协议（重复握手和连接建立和断开开销、臃肿的消息格式等）会极大地增加系统的感知延迟。此外，如果没有流控制语义，当依赖的服务变慢时，单个写得不好的模块可能会导致系统的其余部分超时，从而可能引发重试风暴，给系统带来进一步的压力。[Hystrix](https://github.com/Netflix/Hystrix/wiki#problem) 是一个试图解决同步请求/响应问题的例子，不过要在开销和复杂性上[付出代价](https://github.com/Netflix/Hystrix/wiki/FAQ#what-is-the-processing-overhead-of-using-hystrix)。

此外，选择不当的通信协议会浪费服务器资源（CPU、内存、网络带宽）。虽然这对于较小的部署可能是可以接受的，但具有数百或数千个节点的大型系统会把效率方面一点点的不足放大成千上万倍。使用巨大的内存占用会减少扩展的空间，因为虽然服务器资源相对便宜但也不是无限的。管理大型集群的成本要高得多，而且即使使用好的工具也不够灵活。而且经常被遗忘的是，集群越大，操作就越复杂，这成为可用性问题。

RSocket 寻求：

- 通过支持任何语言和多种传输手段的流量控制，支持非阻塞、双工、异步应用程序通信，减少感知延迟并提高系统效率。

- 通过以下方式减少硬件占用(从而降低成本和操作复杂性)：
   - 通过使用二进制编码提高CPU和内存效率
   - 通过允许持久连接来避免冗余工作

- 通过以下方式减少用户感知延迟：
   - 避免握手和相关的网络往返开销
   - 利用二进制编码减少计算时间
   - 分配更少的内存并降低垃圾收集成本

## 各种对比

下面是在决定建立 RSocket 之前对一些协议的简要评阅。我们并不打算全面或详细地讨论，也不是为了批评各种协议，因为它们在各自领域中都发挥出色。本节仅仅是为了表达现有的协议不能充分满足的需求，从而催生了 RSocket。

背景：

- RSocket 是 OSI 5/6层协议，即 TCP/IP 应用层协议。
- 它的目标是用于行为类似 TCP 的双工二进制传输协议上（[更深入的介绍](./Protocol.md#transport-protocol)）.

#### TCP 和 QUIC

没有帧封装或应用程序语义。必须提供应用程序协议。

#### WebSockets

没有应用程序语义，只有帧封装。必须提供应用程序协议。

#### HTTP/1.1 和 HTTP/2

HTTP 提供了勉强够用的原始功能来构建应用程序协议，但是仍然需要在其基础上定义应用程序协议。它在定义应用程序语义方面是不够的。（[Google 的 GRPC ](https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md)就是一个基于 HTTP/2 的协议的例子，它添加了这类语义）

这些有限的应用语义通常需要一个应用协议来定义以下内容：
  - 对请求使用 GET、POST 或 PUT
  - 使用正常，分块或 SSE 进行响应
  - 负载数据的 MimeType
  - 跟随标准状态码的错误信息
  - 客户端应该如何处理状态码
  - 使用 SSE 作为从服务器到客户端的持久通道，让服务器可以向客户端发送请求

没有定义从响应器（通常是服务器）到请求者（通常是客户端）的流控机制。HTTP/2 在字节级别进行流量控制，而不是在应用程序级别。用于通信请求者（通常是服务器）可用性（例如请求失败）的机制效率低下且令人痛苦。它不支持诸如“即发即弃”之类的交互模型，并且流模型效率低下（块编码或 SSE，这是基于 ASCII 的）。

尽管 REST 无处不在，但单独使用它不足够、也不适合定义应用程序语义。

那么 HTTP/2 呢？它不是解决了 HTTP/1 的问题并迎合了 RSocket 的动机吗？

不走运的是，没有。HTTP/2 对于浏览器和请求/响应文档传输来说要**好得多**，但并没有像本文档前面描述的那样展现应用程序所需的行为和交互模型。

从 [HTTP/2 规范](https://http2.github.io/http2-spec/)和[常见问题](https://http2.github.io/faq/)摘录了一些文字，以方便大家了解 HTTP/2 针对的方向:

（。。。后面的内容与 FAQ 的[相关片段](./FAQ.md#为什么不用-http2)相同）
